{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance Constrains: Balancing univariate moments by introducing additional decision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 23.6.0 23G93)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 13 rows, 20 columns and 112 nonzeros\n",
      "Model fingerprint: 0x0a26da86\n",
      "Variable types: 2 continuous, 18 integer (18 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+00]\n",
      "  Objective range  [1e+00, 8e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+01]\n",
      "Found heuristic solution: objective 28.0000000\n",
      "Presolve removed 3 rows and 1 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 10 rows, 19 columns, 52 nonzeros\n",
      "Variable types: 0 continuous, 19 integer (18 binary)\n",
      "\n",
      "Root relaxation: cutoff, 10 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0     cutoff    0        28.00000   28.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (10 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 28 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.800000000000e+01, best bound 2.800000000000e+01, gap 0.0000%\n",
      "Optimal Matching Found:\n",
      "Treated 1 matched with Control 7\n",
      "Treated 1 matched with Control 9\n",
      "Treated 2 matched with Control 5\n",
      "Treated 2 matched with Control 6\n",
      "Treated 3 matched with Control 4\n",
      "Treated 3 matched with Control 8\n",
      "\n",
      "Covariate imbalance values:\n",
      "z[1] = 0.5\n",
      "z[2] = 0.5\n"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Define sets\n",
    "T = [1, 2, 3]  # Treated units\n",
    "C = [4, 5, 6, 7, 8, 9]  # Control units\n",
    "I = [1, 2]  # Covariates\n",
    "m = 2  # Number of controls per treated unit\n",
    "\n",
    "# Example distances δ_t,c\n",
    "delta = {(t, c): abs(t - c) for t in T for c in C}\n",
    "\n",
    "# Example covariate values (randomized for illustration)\n",
    "x = {\n",
    "    (4, 1): 10, (4, 2): 20, (5, 1): 15, (5, 2): 25,\n",
    "    (6, 1): 12, (6, 2): 22, (7, 1): 11, (7, 2): 21,\n",
    "    (8, 1): 14, (8, 2): 24, (9, 1): 13, (9, 2): 23\n",
    "}\n",
    "\n",
    "# Mean covariate values for treated group (example values)\n",
    "x_T = {1: 13, 2: 23}  # Mean for each covariate in treated group\n",
    "\n",
    "# Covariate importance weights (example)\n",
    "omega = {1: 1.0, 2: 1.0}\n",
    "\n",
    "# Create Gurobi model\n",
    "model = gp.Model(\"Optimal_Matching_Balance\")\n",
    "\n",
    "# Decision variables\n",
    "a = model.addVars(T, C, vtype=GRB.BINARY, name=\"a\")\n",
    "z = model.addVars(I, vtype=GRB.CONTINUOUS, name=\"z\")\n",
    "\n",
    "# Objective function: minimize sum of distances and covariate imbalance\n",
    "model.setObjective(\n",
    "    gp.quicksum(delta[t, c] * a[t, c] for t in T for c in C) +\n",
    "    gp.quicksum(omega[i] * z[i] for i in I),\n",
    "    GRB.MINIMIZE\n",
    ")\n",
    "\n",
    "# Constraint: Each treated unit is matched to exactly m controls\n",
    "for t in T:\n",
    "    model.addConstr(gp.quicksum(a[t, c] for c in C) == m, f\"Match_{t}\")\n",
    "\n",
    "# Constraint: Each control is used at most once\n",
    "for c in C:\n",
    "    model.addConstr(gp.quicksum(a[t, c] for t in T) <= 1, f\"Control_{c}\")\n",
    "\n",
    "# Constraint: Covariate balance constraints\n",
    "for i in I:\n",
    "    model.addConstr(\n",
    "        z[i] >= gp.quicksum(a[t, c] * x[c, i] for t in T for c in C) / (m * len(T)) - x_T[i],\n",
    "        f\"Balance_Pos_{i}\"\n",
    "    )\n",
    "    model.addConstr(\n",
    "        z[i] >= -gp.quicksum(a[t, c] * x[c, i] for t in T for c in C) / (m * len(T)) + x_T[i],\n",
    "        f\"Balance_Neg_{i}\"\n",
    "    )\n",
    "\n",
    "# Solve the model\n",
    "model.optimize()\n",
    "\n",
    "# Print results\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    print(\"Optimal Matching Found:\")\n",
    "    for t in T:\n",
    "        for c in C:\n",
    "            if a[t, c].x > 0.5:  # Selected Matches\n",
    "                print(f\"Treated {t} matched with Control {c}\")\n",
    "    print(\"\\nCovariate imbalance values:\")\n",
    "    for i in I:\n",
    "        print(f\"z[{i}] = {z[i].x}\")\n",
    "else:\n",
    "    print(\"No optimal solution found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance Constrain: Balance the means, second moments (variance), and cross-product correlation of two covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 23.6.0 23G93)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 19 rows, 23 columns and 226 nonzeros\n",
      "Model fingerprint: 0x09b7484f\n",
      "Variable types: 5 continuous, 18 integer (18 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+02]\n",
      "  Objective range  [1e+00, 8e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+02]\n",
      "Found heuristic solution: objective 74.5000000\n",
      "Presolve removed 6 rows and 1 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 13 rows, 22 columns, 100 nonzeros\n",
      "Variable types: 0 continuous, 22 integer (18 binary)\n",
      "\n",
      "Root relaxation: infeasible, 13 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 infeasible    0        74.50000   74.50000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (13 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 74.5 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.449999998510e+01, best bound 7.449999998510e+01, gap 0.0000%\n",
      "Optimal Matching Found:\n",
      "Treated 1 matched with Control 7\n",
      "Treated 1 matched with Control 9\n",
      "Treated 2 matched with Control 5\n",
      "Treated 2 matched with Control 6\n",
      "Treated 3 matched with Control 4\n",
      "Treated 3 matched with Control 8\n",
      "\n",
      "Covariate imbalance values:\n",
      "z[1] = 0.5\n",
      "z[2] = 10.83333332836628\n",
      "z[3] = 0.5\n",
      "z[4] = 20.83333332836628\n",
      "z[5] = 14.83333332836628\n"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Define sets\n",
    "T = [1, 2, 3]  # Treated units\n",
    "C = [4, 5, 6, 7, 8, 9]  # Control units\n",
    "P = [1, 2]  # Covariates (p1 and p2)\n",
    "m = 2  # Number of controls per treated unit\n",
    "\n",
    "# Example distances δ_t,c\n",
    "delta = {(t, c): abs(t - c) for t in T for c in C}\n",
    "\n",
    "# Example covariate values (randomized)\n",
    "x = {\n",
    "    (4, 1): 10, (4, 2): 20, (5, 1): 15, (5, 2): 25,\n",
    "    (6, 1): 12, (6, 2): 22, (7, 1): 11, (7, 2): 21,\n",
    "    (8, 1): 14, (8, 2): 24, (9, 1): 13, (9, 2): 23\n",
    "}\n",
    "\n",
    "# Compute moments for treated units (Example)\n",
    "x_T = {1: 13, 2: 23}  # Mean\n",
    "x2_T = {1: 170, 2: 530}  # Second moment (squared)\n",
    "x_cross_T = 299  # Mean of cross-product x_p1 * x_p2\n",
    "\n",
    "# Covariate importance weights (Ensure all keys 1 to 5 exist)\n",
    "omega = {1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0}\n",
    "\n",
    "# Create Gurobi model\n",
    "model = gp.Model(\"Optimal_Matching_Multivariate\")\n",
    "\n",
    "# Decision variables\n",
    "a = model.addVars(T, C, vtype=GRB.BINARY, name=\"a\")\n",
    "z = model.addVars(range(1, 6), vtype=GRB.CONTINUOUS, name=\"z\")  # Ensured indices 1 to 5\n",
    "\n",
    "# Objective function: Minimize sum of distances and covariate imbalances\n",
    "model.setObjective(\n",
    "    gp.quicksum(delta[t, c] * a[t, c] for t in T for c in C) + gp.quicksum(omega[i] * z[i] for i in range(1, 6)),\n",
    "    GRB.MINIMIZE\n",
    ")\n",
    "\n",
    "# Constraint: Each treated unit is matched to exactly m controls\n",
    "for t in T:\n",
    "    model.addConstr(gp.quicksum(a[t, c] for c in C) == m, f\"Match_{t}\")\n",
    "\n",
    "# Constraint: Each control is used at most once\n",
    "for c in C:\n",
    "    model.addConstr(gp.quicksum(a[t, c] for t in T) <= 1, f\"Control_{c}\")\n",
    "\n",
    "# Covariate balance constraints (Means, Second Moments, Cross Product)\n",
    "model.addConstr(\n",
    "    z[1] >= gp.quicksum(a[t, c] * x[c, 1] for t in T for c in C) / (m * len(T)) - x_T[1],\n",
    "    \"Mean_Balance_p1_Pos\"\n",
    ")\n",
    "model.addConstr(\n",
    "    z[1] >= -gp.quicksum(a[t, c] * x[c, 1] for t in T for c in C) / (m * len(T)) + x_T[1],\n",
    "    \"Mean_Balance_p1_Neg\"\n",
    ")\n",
    "\n",
    "model.addConstr(\n",
    "    z[2] >= gp.quicksum(a[t, c] * x[c, 1]**2 for t in T for c in C) / (m * len(T)) - x2_T[1],\n",
    "    \"SecondMoment_Balance_p1_Pos\"\n",
    ")\n",
    "model.addConstr(\n",
    "    z[2] >= -gp.quicksum(a[t, c] * x[c, 1]**2 for t in T for c in C) / (m * len(T)) + x2_T[1],\n",
    "    \"SecondMoment_Balance_p1_Neg\"\n",
    ")\n",
    "\n",
    "model.addConstr(\n",
    "    z[3] >= gp.quicksum(a[t, c] * x[c, 2] for t in T for c in C) / (m * len(T)) - x_T[2],\n",
    "    \"Mean_Balance_p2_Pos\"\n",
    ")\n",
    "model.addConstr(\n",
    "    z[3] >= -gp.quicksum(a[t, c] * x[c, 2] for t in T for c in C) / (m * len(T)) + x_T[2],\n",
    "    \"Mean_Balance_p2_Neg\"\n",
    ")\n",
    "\n",
    "model.addConstr(\n",
    "    z[4] >= gp.quicksum(a[t, c] * x[c, 2]**2 for t in T for c in C) / (m * len(T)) - x2_T[2],\n",
    "    \"SecondMoment_Balance_p2_Pos\"\n",
    ")\n",
    "model.addConstr(\n",
    "    z[4] >= -gp.quicksum(a[t, c] * x[c, 2]**2 for t in T for c in C) / (m * len(T)) + x2_T[2],\n",
    "    \"SecondMoment_Balance_p2_Neg\"\n",
    ")\n",
    "\n",
    "model.addConstr(\n",
    "    z[5] >= gp.quicksum(a[t, c] * x[c, 1] * x[c, 2] for t in T for c in C) / (m * len(T)) - x_cross_T,\n",
    "    \"CrossProduct_Balance_Pos\"\n",
    ")\n",
    "model.addConstr(\n",
    "    z[5] >= -gp.quicksum(a[t, c] * x[c, 1] * x[c, 2] for t in T for c in C) / (m * len(T)) + x_cross_T,\n",
    "    \"CrossProduct_Balance_Neg\"\n",
    ")\n",
    "\n",
    "# Solve the model\n",
    "model.optimize()\n",
    "\n",
    "# Print results\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    print(\"Optimal Matching Found:\")\n",
    "    for t in T:\n",
    "        for c in C:\n",
    "            if a[t, c].x > 0.5:\n",
    "                print(f\"Treated {t} matched with Control {c}\")\n",
    "    print(\"\\nCovariate imbalance values:\")\n",
    "    for i in range(1, 6):\n",
    "        print(f\"z[{i}] = {z[i].x}\")\n",
    "else:\n",
    "    print(\"No optimal solution found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance Constrain: Incorporate quantile balance and the Kolmogorov-Smirnov (K-S) statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 23.6.0 23G93)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 21 rows, 20 columns and 180 nonzeros\n",
      "Model fingerprint: 0x750ad862\n",
      "Variable types: 2 continuous, 18 integer (18 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-01, 1e+00]\n",
      "  Objective range  [1e+00, 8e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e-01, 2e+00]\n",
      "Found heuristic solution: objective 27.5833333\n",
      "Presolve removed 9 rows and 0 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 12 rows, 20 columns, 84 nonzeros\n",
      "Variable types: 0 continuous, 20 integer (18 binary)\n",
      "\n",
      "Root relaxation: cutoff, 13 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0     cutoff    0        27.58333   27.58333  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (13 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 27.5833 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.758333332837e+01, best bound 2.758333332837e+01, gap 0.0000%\n",
      "Optimal Matching Found:\n",
      "Treated 1 matched with Control 7\n",
      "Treated 1 matched with Control 9\n",
      "Treated 2 matched with Control 5\n",
      "Treated 2 matched with Control 6\n",
      "Treated 3 matched with Control 4\n",
      "Treated 3 matched with Control 8\n",
      "\n",
      "Kolmogorov-Smirnov imbalance values:\n",
      "z[1] = 0.3333333283662796\n",
      "z[2] = 0.25\n"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Define sets\n",
    "T = [1, 2, 3]  # Treated units\n",
    "C = [4, 5, 6, 7, 8, 9]  # Control units\n",
    "P = [1, 2]  # Covariates\n",
    "m = 2  # Number of controls per treated unit\n",
    "\n",
    "# Define quantiles for each covariate\n",
    "G = {1: [10, 15, 20], 2: [20, 25, 30]}  # Example quantile grid for p1 and p2\n",
    "\n",
    "# Example distances δ_t,c\n",
    "delta = {(t, c): abs(t - c) for t in T for c in C}\n",
    "\n",
    "# Example covariate values (randomized)\n",
    "x = {\n",
    "    (4, 1): 10, (4, 2): 20, (5, 1): 15, (5, 2): 25,\n",
    "    (6, 1): 12, (6, 2): 22, (7, 1): 11, (7, 2): 21,\n",
    "    (8, 1): 14, (8, 2): 24, (9, 1): 13, (9, 2): 23\n",
    "}\n",
    "\n",
    "# Compute empirical CDF for treated units at quantiles h_g\n",
    "h = {\n",
    "    1: {10: 0.2, 15: 0.5, 20: 0.8},  # Empirical CDF for covariate 1\n",
    "    2: {20: 0.25, 25: 0.6, 30: 0.9}  # Empirical CDF for covariate 2\n",
    "}\n",
    "\n",
    "# Covariate importance weights\n",
    "omega = {1: 1.0, 2: 1.0}\n",
    "\n",
    "# Create Gurobi model\n",
    "model = gp.Model(\"Optimal_Matching_KS\")\n",
    "\n",
    "# Decision variables\n",
    "a = model.addVars(T, C, vtype=GRB.BINARY, name=\"a\")\n",
    "z = model.addVars(P, vtype=GRB.CONTINUOUS, name=\"z\")\n",
    "\n",
    "# Objective function: Minimize sum of distances and Kolmogorov-Smirnov imbalances\n",
    "model.setObjective(\n",
    "    gp.quicksum(delta[t, c] * a[t, c] for t in T for c in C) +\n",
    "    gp.quicksum(omega[p] * z[p] for p in P),\n",
    "    GRB.MINIMIZE\n",
    ")\n",
    "\n",
    "# Constraint: Each treated unit is matched to exactly m controls\n",
    "for t in T:\n",
    "    model.addConstr(gp.quicksum(a[t, c] for c in C) == m, f\"Match_{t}\")\n",
    "\n",
    "# Constraint: Each control is used at most once\n",
    "for c in C:\n",
    "    model.addConstr(gp.quicksum(a[t, c] for t in T) <= 1, f\"Control_{c}\")\n",
    "\n",
    "# Kolmogorov-Smirnov Constraints\n",
    "for p in P:\n",
    "    for g_p in G[p]:\n",
    "        # Compute indicator function: 1 if x[c, p] < g_p, 0 otherwise\n",
    "        indicator_sum = gp.quicksum(a[t, c] * (1 if x[c, p] < g_p else 0) for t in T for c in C) / (m * len(T))\n",
    "        \n",
    "        # KS Upper Bound Constraint\n",
    "        model.addConstr(omega[p] * z[p] >= h[p][g_p] - indicator_sum, f\"KS_Upper_{p}_{g_p}\")\n",
    "\n",
    "        # KS Lower Bound Constraint\n",
    "        model.addConstr(omega[p] * z[p] >= -h[p][g_p] + indicator_sum, f\"KS_Lower_{p}_{g_p}\")\n",
    "\n",
    "# Solve the model\n",
    "model.optimize()\n",
    "\n",
    "# Print results\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    print(\"Optimal Matching Found:\")\n",
    "    for t in T:\n",
    "        for c in C:\n",
    "            if a[t, c].x > 0.5:\n",
    "                print(f\"Treated {t} matched with Control {c}\")\n",
    "    print(\"\\nKolmogorov-Smirnov imbalance values:\")\n",
    "    for p in P:\n",
    "        print(f\"z[{p}] = {z[p].x}\")\n",
    "else:\n",
    "    print(\"No optimal solution found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance Constrain: Exact and near-exact matching constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 23.6.0 23G93)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 17 rows, 20 columns and 69 nonzeros\n",
      "Model fingerprint: 0xec2582d3\n",
      "Variable types: 2 continuous, 18 integer (18 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 8e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 4e+00]\n",
      "Presolve removed 8 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 0\n",
      "\n",
      "Model is infeasible\n",
      "Best objective -, best bound -, gap -\n",
      "No optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Define sets\n",
    "T = [1, 2, 3]  # Treated units\n",
    "C = [4, 5, 6, 7, 8, 9]  # Control units\n",
    "B = [0, 1]  # Categories of a nominal covariate\n",
    "m = 2  # Number of controls per treated unit\n",
    "xi = 2  # Allowed deviation for near-exact matching\n",
    "\n",
    "# Example categorical covariate values for treated and control groups\n",
    "x_cat = {\n",
    "    1: 0, 2: 1, 3: 0,  # Treated\n",
    "    4: 0, 5: 1, 6: 1, 7: 0, 8: 0, 9: 1  # Control\n",
    "}\n",
    "\n",
    "# Example distances δ_t,c\n",
    "delta = {(t, c): abs(t - c) for t in T for c in C}\n",
    "\n",
    "# Create Gurobi model\n",
    "model = gp.Model(\"Optimal_Matching_Exact\")\n",
    "\n",
    "# Decision variables\n",
    "a = model.addVars(T, C, vtype=GRB.BINARY, name=\"a\")\n",
    "u = model.addVars(B, vtype=GRB.CONTINUOUS, name=\"u\")  # Auxiliary variables for near-exact matching\n",
    "\n",
    "# Objective function: Minimize total distance\n",
    "model.setObjective(\n",
    "    gp.quicksum(delta[t, c] * a[t, c] for t in T for c in C),\n",
    "    GRB.MINIMIZE\n",
    ")\n",
    "\n",
    "# Constraint: Each treated unit is matched to exactly m controls\n",
    "for t in T:\n",
    "    model.addConstr(gp.quicksum(a[t, c] for c in C) == m, f\"Match_{t}\")\n",
    "\n",
    "# Constraint: Each control is used at most once\n",
    "for c in C:\n",
    "    model.addConstr(gp.quicksum(a[t, c] for t in T) <= 1, f\"Control_{c}\")\n",
    "\n",
    "# **Exact Matching Constraint**\n",
    "for b in B:\n",
    "    model.addConstr(\n",
    "        gp.quicksum(a[t, c] * (1 if x_cat[t] == b and x_cat[c] == b else 0) for t in T for c in C)\n",
    "        == m * sum(1 for t in T if x_cat[t] == b),\n",
    "        f\"Exact_Matching_{b}\"\n",
    "    )\n",
    "\n",
    "# **Near-Exact Matching Constraint using auxiliary variable**\n",
    "for b in B:\n",
    "    model.addConstr(\n",
    "        u[b] >= gp.quicksum(a[t, c] * (1 if x_cat[t] == b and x_cat[c] == b else 0) for t in T for c in C)\n",
    "        - m * sum(1 for t in T if x_cat[t] == b),\n",
    "        f\"Near_Exact_Matching_Upper_{b}\"\n",
    "    )\n",
    "\n",
    "    model.addConstr(\n",
    "        u[b] >= -gp.quicksum(a[t, c] * (1 if x_cat[t] == b and x_cat[c] == b else 0) for t in T for c in C)\n",
    "        + m * sum(1 for t in T if x_cat[t] == b),\n",
    "        f\"Near_Exact_Matching_Lower_{b}\"\n",
    "    )\n",
    "\n",
    "    model.addConstr(u[b] <= xi, f\"Near_Exact_Bound_{b}\")\n",
    "\n",
    "# Solve the model\n",
    "model.optimize()\n",
    "\n",
    "# Print results\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    print(\"Optimal Matching Found:\")\n",
    "    for t in T:\n",
    "        for c in C:\n",
    "            if a[t, c].x > 0.5:\n",
    "                print(f\"Treated {t} matched with Control {c}\")\n",
    "else:\n",
    "    print(\"No optimal solution found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Setup and Weighting Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rseed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effects Estimates:\n",
      "\n",
      "  Factor  Estimated Main Effect\n",
      "0    z_1               1.006173\n",
      "1    z_2              -0.137883\n",
      "2    z_3              -0.429061\n",
      "\n",
      "Interaction Effects Estimates:\n",
      "\n",
      "  Interaction  Estimated Effect\n",
      "0   z_1 & z_2          0.173369\n",
      "1   z_1 & z_3          0.471227\n",
      "2   z_2 & z_3         -0.198338\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the parameters\n",
    "K = 3  # Number of binary factors\n",
    "Q = 2 ** K  # Number of possible treatment combinations\n",
    "N = 1000  # Number of subjects\n",
    "\n",
    "# Generate all possible treatment combinations\n",
    "treatment_combinations = np.array(list(itertools.product([-1, 1], repeat=K)))\n",
    "\n",
    "# Simulate covariates X (D-dimensional, here D=3 for simplicity)\n",
    "D = 3\n",
    "X = np.random.normal(0, 1, size=(N, D))\n",
    "\n",
    "# Simulate potential outcomes for each individual and each treatment combination\n",
    "# Assume potential outcomes depend on treatment and covariates linearly\n",
    "beta_treatment = np.random.randn(Q)  # Random effect size for each treatment combination\n",
    "beta_covariate = np.random.randn(D)  # Effect size for covariates\n",
    "\n",
    "# For each subject, generate potential outcomes\n",
    "Y_potential = np.zeros((N, Q))\n",
    "for i in range(N):\n",
    "    for q in range(Q):\n",
    "        Y_potential[i, q] = beta_treatment[q] + X[i].dot(beta_covariate) + np.random.normal(0, 1)\n",
    "\n",
    "# Assign each individual a random treatment from the possible combinations\n",
    "Z_indices = np.random.choice(Q, size=N)  # Random treatment assignment\n",
    "Y_observed = np.array([Y_potential[i, Z_indices[i]] for i in range(N)])  # Observed outcome\n",
    "\n",
    "# Estimate main effects\n",
    "# Contrast vector for each factor\n",
    "main_effects = []\n",
    "for k in range(K):\n",
    "    g_k = np.array([1 if comb[k] == 1 else -1 for comb in treatment_combinations])\n",
    "    E_Y = np.array([np.mean(Y_observed[Z_indices == q]) if np.any(Z_indices == q) else 0 for q in range(Q)])\n",
    "    tau_k = (1 / (2 ** (K - 1))) * g_k.T @ E_Y\n",
    "    main_effects.append(tau_k)\n",
    "\n",
    "# Estimate interaction effects between two factors\n",
    "interaction_effects = {}\n",
    "for k1, k2 in itertools.combinations(range(K), 2):\n",
    "    g_k1 = np.array([1 if comb[k1] == 1 else -1 for comb in treatment_combinations])\n",
    "    g_k2 = np.array([1 if comb[k2] == 1 else -1 for comb in treatment_combinations])\n",
    "    g_interaction = g_k1 * g_k2\n",
    "    tau_k1k2 = (1 / (2 ** (K - 1))) * g_interaction @ E_Y\n",
    "    interaction_effects[(k1, k2)] = tau_k1k2\n",
    "\n",
    "# Present results\n",
    "results = {\n",
    "    \"Main Effects\": main_effects,\n",
    "    \"Interaction Effects\": interaction_effects\n",
    "}\n",
    "\n",
    "# Convert results to DataFrame for display\n",
    "main_effects_df = pd.DataFrame({\n",
    "    'Factor': [f'z_{k+1}' for k in range(K)],\n",
    "    'Estimated Main Effect': main_effects\n",
    "})\n",
    "\n",
    "interaction_effects_df = pd.DataFrame(\n",
    "    [(f'z_{k1+1} & z_{k2+1}', effect) for (k1, k2), effect in interaction_effects.items()],\n",
    "    columns=['Interaction', 'Estimated Effect']\n",
    ")\n",
    "\n",
    "# Display the DataFrames using standard methods\n",
    "print(\"Main Effects Estimates:\\n\")\n",
    "print(main_effects_df)\n",
    "\n",
    "print(\"\\nInteraction Effects Estimates:\\n\")\n",
    "print(interaction_effects_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighting for Observational Factorial Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Main Effects Using Weighting Estimator:\n",
      "   Factor  Weighted Effect\n",
      "0    z_1         1.709458\n",
      "1    z_2         0.775540\n",
      "2    z_3        -0.650236\n",
      "\n",
      "Weighted Interaction Effects Using Weighting Estimator:\n",
      "   Interaction  Weighted Effect\n",
      "0   z_1 & z_2         0.997883\n",
      "1   z_1 & z_3         0.549006\n",
      "2   z_2 & z_3        -1.254974\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Parameters\n",
    "K = 3  # Number of binary factors\n",
    "Q = 2 ** K  # Number of treatment combinations\n",
    "N = 1000  # Number of individuals\n",
    "\n",
    "# Generate treatment combinations\n",
    "treatment_combinations = np.array(list(itertools.product([-1, 1], repeat=K)))\n",
    "\n",
    "# Simulate covariates X (D-dimensional)\n",
    "D = 3\n",
    "X = np.random.normal(0, 1, size=(N, D))\n",
    "\n",
    "# Simulate potential outcomes\n",
    "beta_treatment = np.random.randn(Q)  # Random effects for each treatment combination\n",
    "beta_covariate = np.random.randn(D)  # Effects for covariates\n",
    "\n",
    "Y_potential = np.zeros((N, Q))\n",
    "for i in range(N):\n",
    "    for q in range(Q):\n",
    "        Y_potential[i, q] = beta_treatment[q] + X[i].dot(beta_covariate) + np.random.normal(0, 1)\n",
    "\n",
    "# Random assignment of treatments\n",
    "Z_indices = np.random.choice(Q, size=N)  # Random treatment assignment\n",
    "Y_observed = np.array([Y_potential[i, Z_indices[i]] for i in range(N)])  # Observed outcomes\n",
    "\n",
    "# Simulate f(X) and f_z(X) for weighting function\n",
    "# Assume f(X) is standard normal and f_z(X) shifts mean for treatment groups\n",
    "f_X = norm.pdf(X)\n",
    "f_z = np.zeros(N)\n",
    "for i in range(N):\n",
    "    z_idx = Z_indices[i]\n",
    "    treatment_effect = treatment_combinations[z_idx]\n",
    "    shifted_mean = treatment_effect * 0.5  # Shifted by treatment effect\n",
    "    f_z[i] = np.prod(norm.pdf(X[i], loc=shifted_mean, scale=1))\n",
    "\n",
    "# Weighting function w_z(X) = f(X) / f_z(X)\n",
    "w_z = np.prod(f_X, axis=1) / f_z\n",
    "w_i = N * w_z / (2 ** (K - 1) * np.bincount(Z_indices, minlength=Q)[Z_indices])\n",
    "\n",
    "# Calculate the weighting estimator for factorial effects\n",
    "weighted_effects = []\n",
    "for k in range(K):\n",
    "    g_k = np.array([1 if comb[k] == 1 else -1 for comb in treatment_combinations])\n",
    "    g_k_pos = np.maximum(g_k, 0)\n",
    "    g_k_neg = np.maximum(-g_k, 0)\n",
    "\n",
    "    # A_iK^+ and A_iK^-\n",
    "    A_iK_pos = np.array([np.sum([g_k_pos[q] * (Z_indices[i] == q) for q in range(Q)]) for i in range(N)])\n",
    "    A_iK_neg = 1 - A_iK_pos\n",
    "\n",
    "    # Weighted estimators for tau_K^+ and tau_K^-\n",
    "    tau_k_pos = (1 / N) * np.sum(w_i * A_iK_pos * Y_observed)\n",
    "    tau_k_neg = (1 / N) * np.sum(w_i * A_iK_neg * Y_observed)\n",
    "\n",
    "    # Combine to get the weighted factorial effect\n",
    "    tau_k_weighted = tau_k_pos - tau_k_neg\n",
    "    weighted_effects.append(tau_k_weighted)\n",
    "\n",
    "# Interaction effects using the weighting estimator\n",
    "interaction_effects_weighted = {}\n",
    "for k1, k2 in itertools.combinations(range(K), 2):\n",
    "    g_k1 = np.array([1 if comb[k1] == 1 else -1 for comb in treatment_combinations])\n",
    "    g_k2 = np.array([1 if comb[k2] == 1 else -1 for comb in treatment_combinations])\n",
    "    g_interaction = g_k1 * g_k2\n",
    "\n",
    "    g_interaction_pos = np.maximum(g_interaction, 0)\n",
    "    g_interaction_neg = np.maximum(-g_interaction, 0)\n",
    "\n",
    "    A_iK_pos = np.array([np.sum([g_interaction_pos[q] * (Z_indices[i] == q) for q in range(Q)]) for i in range(N)])\n",
    "    A_iK_neg = 1 - A_iK_pos\n",
    "\n",
    "    tau_inter_pos = (1 / N) * np.sum(w_i * A_iK_pos * Y_observed)\n",
    "    tau_inter_neg = (1 / N) * np.sum(w_i * A_iK_neg * Y_observed)\n",
    "\n",
    "    tau_inter_weighted = tau_inter_pos - tau_inter_neg\n",
    "    interaction_effects_weighted[(k1, k2)] = tau_inter_weighted\n",
    "\n",
    "# Prepare results\n",
    "weighted_main_effects_df = pd.DataFrame({\n",
    "    'Factor': [f'z_{k+1}' for k in range(K)],\n",
    "    'Weighted Effect': weighted_effects\n",
    "})\n",
    "\n",
    "weighted_interaction_effects_df = pd.DataFrame(\n",
    "    [(f'z_{k1+1} & z_{k2+1}', effect) for (k1, k2), effect in interaction_effects_weighted.items()],\n",
    "    columns=['Interaction', 'Weighted Effect']\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Weighted Main Effects Using Weighting Estimator:\\n\", weighted_main_effects_df)\n",
    "print(\"\\nWeighted Interaction Effects Using Weighting Estimator:\\n\", weighted_interaction_effects_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Weighting for Estimating a Single Factorial Effect \n",
    "\n",
    "3.1.1 General Additive Outcome Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model assumes outcomes are affected by both covariates and factorial interactions.\n",
    "\n",
    "The weighting balances both: Covariates across treatment assignments and Higher-order interactions that can bias the factorial effect estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Main Effects Using New Weighting Estimator:\n",
      "   Factor  Weighted Effect\n",
      "0    z_1        -2.700076\n",
      "1    z_2        -4.358818\n",
      "2    z_3        -2.682912\n",
      "\n",
      "Weighted Interaction Effects Using New Weighting Estimator:\n",
      "   Interaction  Weighted Effect\n",
      "0   z_1 & z_2        -1.531859\n",
      "1   z_1 & z_3        -0.467510\n",
      "2   z_2 & z_3        -1.249908\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Parameters\n",
    "K = 3  # Number of binary factors\n",
    "Q = 2 ** K  # Number of treatment combinations\n",
    "N = 1000  # Number of individuals\n",
    "\n",
    "# Generate treatment combinations\n",
    "treatment_combinations = np.array(list(itertools.product([-1, 1], repeat=K)))\n",
    "\n",
    "# Simulate covariates X (D-dimensional)\n",
    "D = 3\n",
    "X = np.random.normal(0, 1, size=(N, D))\n",
    "\n",
    "# Simulate potential outcomes using a general additive model\n",
    "S = 3  # Number of basis functions\n",
    "alpha = np.random.randn(S)\n",
    "beta = np.random.randn(Q)\n",
    "\n",
    "# Define basis functions h_s(X) = X^s (simple polynomial basis)\n",
    "def h_s(X, s):\n",
    "    return X ** (s + 1)\n",
    "\n",
    "# Compute mu(X) and nu(z)\n",
    "mu_X = np.sum([alpha[s] * h_s(X, s).sum(axis=1) for s in range(S)], axis=0)\n",
    "nu_z = np.zeros((N, Q))\n",
    "for i in range(N):\n",
    "    for q in range(Q):\n",
    "        z = treatment_combinations[q]\n",
    "        nu_z[i, q] = beta[q] * np.prod(z)\n",
    "\n",
    "# Simulate potential outcomes with reshaping for broadcasting\n",
    "Y_potential = mu_X[:, np.newaxis] + nu_z + np.random.normal(0, 1, size=(N, Q))\n",
    "\n",
    "\n",
    "# Random assignment of treatments\n",
    "Z_indices = np.random.choice(Q, size=N)\n",
    "Y_observed = np.array([Y_potential[i, Z_indices[i]] for i in range(N)])\n",
    "\n",
    "# Simulate f(X) and f_z(X) for weighting\n",
    "f_X = norm.pdf(X)\n",
    "f_z = np.zeros(N)\n",
    "for i in range(N):\n",
    "    z_idx = Z_indices[i]\n",
    "    treatment_effect = treatment_combinations[z_idx]\n",
    "    shifted_mean = treatment_effect * 0.5\n",
    "    f_z[i] = np.prod(norm.pdf(X[i], loc=shifted_mean, scale=1))\n",
    "\n",
    "# Weighting function\n",
    "w_z = np.prod(f_X, axis=1) / f_z\n",
    "w_i = N * w_z / (2 ** (K - 1) * np.bincount(Z_indices, minlength=Q)[Z_indices])\n",
    "\n",
    "# Calculate the new weighting estimator\n",
    "weighted_effects = []\n",
    "for k in range(K):\n",
    "    g_k = np.array([1 if comb[k] == 1 else -1 for comb in treatment_combinations])\n",
    "    g_k_pos = np.maximum(g_k, 0)\n",
    "    g_k_neg = np.maximum(-g_k, 0)\n",
    "\n",
    "    # A_iK^+ and A_iK^-\n",
    "    A_iK_pos = np.array([np.sum([g_k_pos[q] * (Z_indices[i] == q) for q in range(Q)]) for i in range(N)])\n",
    "    A_iK_neg = 1 - A_iK_pos\n",
    "\n",
    "    # Weighted estimators for tau_K^+ and tau_K^-\n",
    "    tau_k_pos = (1 / N) * np.sum(w_i * A_iK_pos * Y_observed)\n",
    "    tau_k_neg = (1 / N) * np.sum(w_i * A_iK_neg * Y_observed)\n",
    "\n",
    "    # Combine to get the weighted factorial effect\n",
    "    tau_k_weighted = tau_k_pos - tau_k_neg\n",
    "    weighted_effects.append(tau_k_weighted)\n",
    "\n",
    "# Interaction effects using the new weighting estimator\n",
    "interaction_effects_weighted = {}\n",
    "for k1, k2 in itertools.combinations(range(K), 2):\n",
    "    g_k1 = np.array([1 if comb[k1] == 1 else -1 for comb in treatment_combinations])\n",
    "    g_k2 = np.array([1 if comb[k2] == 1 else -1 for comb in treatment_combinations])\n",
    "    g_interaction = g_k1 * g_k2\n",
    "\n",
    "    g_interaction_pos = np.maximum(g_interaction, 0)\n",
    "    g_interaction_neg = np.maximum(-g_interaction, 0)\n",
    "\n",
    "    A_iK_pos = np.array([np.sum([g_interaction_pos[q] * (Z_indices[i] == q) for q in range(Q)]) for i in range(N)])\n",
    "    A_iK_neg = 1 - A_iK_pos\n",
    "\n",
    "    tau_inter_pos = (1 / N) * np.sum(w_i * A_iK_pos * Y_observed)\n",
    "    tau_inter_neg = (1 / N) * np.sum(w_i * A_iK_neg * Y_observed)\n",
    "\n",
    "    tau_inter_weighted = tau_inter_pos - tau_inter_neg\n",
    "    interaction_effects_weighted[(k1, k2)] = tau_inter_weighted\n",
    "\n",
    "# Prepare results\n",
    "weighted_main_effects_df = pd.DataFrame({\n",
    "    'Factor': [f'z_{k+1}' for k in range(K)],\n",
    "    'Weighted Effect': weighted_effects\n",
    "})\n",
    "\n",
    "weighted_interaction_effects_df = pd.DataFrame(\n",
    "    [(f'z_{k1+1} & z_{k2+1}', effect) for (k1, k2), effect in interaction_effects_weighted.items()],\n",
    "    columns=['Interaction', 'Weighted Effect']\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Weighted Main Effects Using New Weighting Estimator:\\n\", weighted_main_effects_df)\n",
    "print(\"\\nWeighted Interaction Effects Using New Weighting Estimator:\\n\", weighted_interaction_effects_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.2 Outcome Model with Treatment Effect Heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Main Effects with Heterogeneity:\n",
      "   Factor  Weighted Effect\n",
      "0    z_1       -11.910414\n",
      "1    z_2       -11.442368\n",
      "2    z_3        -4.497607\n",
      "\n",
      "Weighted Interaction Effects with Heterogeneity:\n",
      "   Interaction  Weighted Effect\n",
      "0   z_1 & z_2       -19.377291\n",
      "1   z_1 & z_3        -8.112643\n",
      "2   z_2 & z_3        -2.841704\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Parameters\n",
    "K = 3  # Number of binary factors\n",
    "Q = 2 ** K  # Number of treatment combinations\n",
    "N = 1000  # Number of individuals\n",
    "\n",
    "# Generate treatment combinations\n",
    "treatment_combinations = np.array(list(itertools.product([-1, 1], repeat=K)))\n",
    "\n",
    "# Simulate covariates X (D-dimensional)\n",
    "D = 3\n",
    "X = np.random.normal(0, 1, size=(N, D))\n",
    "\n",
    "# Simulate potential outcomes using heterogeneous treatment effects\n",
    "S = 3  # Number of basis functions\n",
    "alpha = np.random.randn(S, Q)  # Different coefficients for each treatment\n",
    "beta = np.random.randn(Q)\n",
    "\n",
    "# Define basis functions h_s(X) = X^s (polynomial basis)\n",
    "def h_s(X, s):\n",
    "    return X ** (s + 1)\n",
    "\n",
    "# Define heterogeneous basis functions q_sJ(X, z)\n",
    "def q_sJ(X, z, s):\n",
    "    return h_s(X, s) * np.prod(z)\n",
    "\n",
    "# Compute mu(X, z) with heterogeneity\n",
    "mu_XZ = np.zeros((N, Q))\n",
    "for i in range(N):\n",
    "    for q in range(Q):\n",
    "        z = treatment_combinations[q]\n",
    "        mu_XZ[i, q] = sum([alpha[s, q] * h_s(X[i], s).sum() for s in range(S)])\n",
    "\n",
    "# Simulate nu(z)\n",
    "nu_z = np.zeros((N, Q))\n",
    "for i in range(N):\n",
    "    for q in range(Q):\n",
    "        z = treatment_combinations[q]\n",
    "        nu_z[i, q] = beta[q] * np.prod(z)\n",
    "\n",
    "# Generate potential outcomes\n",
    "Y_potential = mu_XZ + nu_z + np.random.normal(0, 1, size=(N, Q))\n",
    "\n",
    "# Random assignment of treatments\n",
    "Z_indices = np.random.choice(Q, size=N)\n",
    "Y_observed = np.array([Y_potential[i, Z_indices[i]] for i in range(N)])\n",
    "\n",
    "# Simulate f(X) and f_z(X) for weighting function\n",
    "f_X = norm.pdf(X)\n",
    "f_z = np.zeros(N)\n",
    "for i in range(N):\n",
    "    z_idx = Z_indices[i]\n",
    "    treatment_effect = treatment_combinations[z_idx]\n",
    "    shifted_mean = treatment_effect * 0.5\n",
    "    f_z[i] = np.prod(norm.pdf(X[i], loc=shifted_mean, scale=1))\n",
    "\n",
    "# Weighting function\n",
    "w_z = np.prod(f_X, axis=1) / f_z\n",
    "w_i = N * w_z / (2 ** (K - 1) * np.bincount(Z_indices, minlength=Q)[Z_indices])\n",
    "\n",
    "# Calculate the weighting estimator with heterogeneity\n",
    "weighted_effects = []\n",
    "for k in range(K):\n",
    "    g_k = np.array([1 if comb[k] == 1 else -1 for comb in treatment_combinations])\n",
    "    g_k_pos = np.maximum(g_k, 0)\n",
    "    g_k_neg = np.maximum(-g_k, 0)\n",
    "\n",
    "    # A_iK^+ and A_iK^-\n",
    "    A_iK_pos = np.array([np.sum([g_k_pos[q] * (Z_indices[i] == q) for q in range(Q)]) for i in range(N)])\n",
    "    A_iK_neg = 1 - A_iK_pos\n",
    "\n",
    "    # Weighted estimators for tau_K^+ and tau_K^-\n",
    "    tau_k_pos = (1 / N) * np.sum(w_i * A_iK_pos * Y_observed)\n",
    "    tau_k_neg = (1 / N) * np.sum(w_i * A_iK_neg * Y_observed)\n",
    "\n",
    "    # Combine to get the weighted factorial effect\n",
    "    tau_k_weighted = tau_k_pos - tau_k_neg\n",
    "    weighted_effects.append(tau_k_weighted)\n",
    "\n",
    "# Interaction effects with heterogeneity\n",
    "interaction_effects_weighted = {}\n",
    "for k1, k2 in itertools.combinations(range(K), 2):\n",
    "    g_k1 = np.array([1 if comb[k1] == 1 else -1 for comb in treatment_combinations])\n",
    "    g_k2 = np.array([1 if comb[k2] == 1 else -1 for comb in treatment_combinations])\n",
    "    g_interaction = g_k1 * g_k2\n",
    "\n",
    "    g_interaction_pos = np.maximum(g_interaction, 0)\n",
    "    g_interaction_neg = np.maximum(-g_interaction, 0)\n",
    "\n",
    "    A_iK_pos = np.array([np.sum([g_interaction_pos[q] * (Z_indices[i] == q) for q in range(Q)]) for i in range(N)])\n",
    "    A_iK_neg = 1 - A_iK_pos\n",
    "\n",
    "    tau_inter_pos = (1 / N) * np.sum(w_i * A_iK_pos * Y_observed)\n",
    "    tau_inter_neg = (1 / N) * np.sum(w_i * A_iK_neg * Y_observed)\n",
    "\n",
    "    tau_inter_weighted = tau_inter_pos - tau_inter_neg\n",
    "    interaction_effects_weighted[(k1, k2)] = tau_inter_weighted\n",
    "\n",
    "# Prepare results\n",
    "weighted_main_effects_df = pd.DataFrame({\n",
    "    'Factor': [f'z_{k+1}' for k in range(K)],\n",
    "    'Weighted Effect': weighted_effects\n",
    "})\n",
    "\n",
    "weighted_interaction_effects_df = pd.DataFrame(\n",
    "    [(f'z_{k1+1} & z_{k2+1}', effect) for (k1, k2), effect in interaction_effects_weighted.items()],\n",
    "    columns=['Interaction', 'Weighted Effect']\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Weighted Main Effects with Heterogeneity:\\n\", weighted_main_effects_df)\n",
    "print(\"\\nWeighted Interaction Effects with Heterogeneity:\\n\", weighted_interaction_effects_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Weighting for Estimating Multiple Factorial Effects Simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 23.6.0 23G93)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 5 rows, 200 columns and 1000 nonzeros\n",
      "Model fingerprint: 0x11a6f028\n",
      "Model has 200 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-03, 4e+00]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  QObjective range [2e+00, 2e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [0e+00, 0e+00]\n",
      "Presolve time: 0.01s\n",
      "Presolved: 5 rows, 200 columns, 1000 nonzeros\n",
      "Presolved model has 200 quadratic objective terms\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 1.000e+01\n",
      " Factor NZ  : 1.500e+01\n",
      " Factor Ops : 5.500e+01 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   5.00000000e+07 -5.00000000e+07  3.87e+04 0.00e+00  1.00e+06     0s\n",
      "   1   1.38158452e+07 -1.38158452e+07  1.19e+03 1.43e+01  1.51e+05     0s\n",
      "   2   2.20907181e+06 -2.20907181e+06  1.19e-03 0.00e+00  2.21e+04     0s\n",
      "   3   3.23651857e+05 -3.23651857e+05  1.19e-09 0.00e+00  3.24e+03     0s\n",
      "   4   4.74183265e+04 -4.74183265e+04  7.44e-13 4.26e-14  4.74e+02     0s\n",
      "   5   6.94727187e+03 -6.94727187e+03  5.49e-13 1.51e-14  6.95e+01     0s\n",
      "   6   1.01784658e+03 -1.01784658e+03  5.53e-14 4.66e-15  1.02e+01     0s\n",
      "   7   1.49124951e+02 -1.49124951e+02  7.11e-14 1.33e-15  1.49e+00     0s\n",
      "   8   2.18483309e+01 -2.18483309e+01  1.41e-14 6.94e-16  2.18e-01     0s\n",
      "   9   3.20100375e+00 -3.20100375e+00  7.16e-15 2.08e-16  3.20e-02     0s\n",
      "  10   4.68979728e-01 -4.68979728e-01  1.67e-15 9.71e-17  4.69e-03     0s\n",
      "  11   6.87103133e-02 -6.87103133e-02  4.93e-16 4.34e-17  6.87e-04     0s\n",
      "  12   1.00667611e-02 -1.00667611e-02  3.83e-16 2.43e-17  1.01e-04     0s\n",
      "  13   1.47488300e-03 -1.47488300e-03  1.17e-16 5.20e-18  1.47e-05     0s\n",
      "  14   2.16085365e-04 -2.16085365e-04  1.80e-17 2.44e-18  2.16e-06     0s\n",
      "  15   3.16587030e-05 -3.16587030e-05  1.04e-17 1.54e-18  3.17e-07     0s\n",
      "  16   4.63832167e-06 -4.63832167e-06  6.15e-18 2.44e-19  4.64e-08     0s\n",
      "  17   6.79561227e-07 -6.79561227e-07  7.11e-18 1.39e-19  6.80e-09     0s\n",
      "  18   9.95626169e-08 -9.95626169e-08  1.99e-18 6.44e-20  9.96e-10     0s\n",
      "  19   1.45869334e-08 -1.45869334e-08  2.69e-19 2.03e-20  1.46e-10     0s\n",
      "  20   2.13713365e-09 -2.13713365e-09  1.83e-19 6.56e-21  2.14e-11     0s\n",
      "\n",
      "Barrier solved model in 20 iterations and 0.03 seconds (0.00 work units)\n",
      "Optimal objective 2.13713365e-09\n",
      "\n",
      "Weighted Expected Outcomes:\n",
      "Weighted E[Y1]: 2.246950101786268\n",
      "Weighted E[Y2]: 1.2929983228108735\n",
      "Weighted E[Y3]: 0.9268150563338297\n",
      "\n",
      "Covariate Balance After Weighting (Standardized Mean Differences):\n",
      "         Z1        Z2        Z3\n",
      "0  0.010293  0.903805  0.914416\n",
      "1  0.014170  0.606045  0.315237\n",
      "2  0.007236  1.179601  0.874816\n",
      "3  0.006528  0.317556  0.571239\n",
      "4  0.008002  0.432347  0.554586\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Parameters\n",
    "N = 200  # Sample size\n",
    "K = 3  # Number of binary factors\n",
    "D = 5  # Number of covariates\n",
    "rho = 0.2  # Covariance correlation\n",
    "\n",
    "# Generate multivariate normal covariates X with mean mu and covariance Sigma\n",
    "mu = np.array([0.1, 0.1, 0.1, 0.0, 0.0])\n",
    "Sigma = np.full((D, D), rho)\n",
    "np.fill_diagonal(Sigma, 1)\n",
    "\n",
    "# Logistic regression coefficients for Z\n",
    "beta1 = np.array([1/4, 2/4, 0, 3/4, 1])\n",
    "beta2 = np.array([3/4, 1/4, 1, 0, 2/4])\n",
    "beta3 = np.array([1, 0, 3/4, 2/4, 1/4])\n",
    "\n",
    "# Generate covariates X\n",
    "X = multivariate_normal.rvs(mean=mu, cov=Sigma, size=N)\n",
    "\n",
    "# Generate treatment assignment Z based on logistic regression\n",
    "def logistic_prob(X, beta):\n",
    "    logits = X @ beta\n",
    "    return 1 / (1 + np.exp(-logits))\n",
    "\n",
    "Z = np.zeros((N, K))\n",
    "for k, beta in enumerate([beta1, beta2, beta3]):\n",
    "    probs = logistic_prob(X, beta)\n",
    "    Z[:, k] = np.random.binomial(1, probs)\n",
    "\n",
    "Z_expanded = np.repeat(Z, D // K + 1, axis=1)[:, :D] \n",
    "\n",
    "# Generate potential outcomes\n",
    "epsilon = np.random.normal(0, 1, size=(N, 3))\n",
    "Y1 = 2 * np.sum(X, axis=1) + np.sum(Z, axis=1) + epsilon[:, 0]\n",
    "Y2 = 2 * np.sum(X, axis=1) + np.sum(X * Z_expanded, axis=1) + epsilon[:, 1]\n",
    "Y3 = np.sin(X[:, 0]) + np.cos(X[:, 1]) + (np.minimum(1, Y1) + X[:, 1]) * Z[:, 0] + np.sum(X * Z_expanded, axis=1) + epsilon[:, 2]\n",
    "# Initialize Gurobi model\n",
    "model = gp.Model(\"weight_optimization\")\n",
    "\n",
    "# Add variables (weights)\n",
    "w = model.addVars(N, lb=0.0, name=\"w\")\n",
    "\n",
    "# Objective: Minimize variance of weights (sum of squared weights)\n",
    "model.setObjective(gp.quicksum(w[i] * w[i] for i in range(N)), GRB.MINIMIZE)\n",
    "\n",
    "# Balance constraints (Standardized Mean Differences close to 0)\n",
    "# Linear balance constraints (avoid non-linear operations)\n",
    "for d in range(D):\n",
    "    treated_sum = gp.quicksum(w[i] * X[i, d] * Z[i, 0] for i in range(N))\n",
    "    control_sum = gp.quicksum(w[i] * X[i, d] * (1 - Z[i, 0]) for i in range(N))\n",
    "    model.addConstr(treated_sum - control_sum == 0, name=f\"balance_{d}\")\n",
    "\n",
    "# Solve the optimization problem\n",
    "model.optimize()\n",
    "\n",
    "# Extract the optimal weights\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    w_opt = np.array([w[i].X for i in range(N)])\n",
    "else:\n",
    "    raise ValueError(\"Optimization did not converge!\")\n",
    "\n",
    "# Apply optimal weights to outcomes\n",
    "weighted_Y1 = np.sum(w_opt * Y1) / np.sum(w_opt)\n",
    "weighted_Y2 = np.sum(w_opt * Y2) / np.sum(w_opt)\n",
    "weighted_Y3 = np.sum(w_opt * Y3) / np.sum(w_opt)\n",
    "\n",
    "# Check covariate balance using standardized mean differences after weighting\n",
    "def compute_smd_weighted(X, Z_col, weights):\n",
    "    treated_mean = np.average(X[Z_col == 1], axis=0, weights=weights[Z_col == 1])\n",
    "    control_mean = np.average(X[Z_col == 0], axis=0, weights=weights[Z_col == 0])\n",
    "    pooled_sd = np.sqrt((np.average((X[Z_col == 1] - treated_mean) ** 2, axis=0, weights=weights[Z_col == 1]) +\n",
    "                         np.average((X[Z_col == 0] - control_mean) ** 2, axis=0, weights=weights[Z_col == 0])) / 2)\n",
    "    smd = np.abs(treated_mean - control_mean) / pooled_sd\n",
    "    return smd\n",
    "\n",
    "# Evaluate SMDs after weighting\n",
    "smd_weighted_results = {}\n",
    "for k in range(K):\n",
    "    smd_weighted_results[f'Z{k+1}'] = compute_smd_weighted(X, Z[:, k], w_opt)\n",
    "\n",
    "smd_weighted_df = pd.DataFrame(smd_weighted_results)\n",
    "\n",
    "# Display results\n",
    "print(\"Weighted Expected Outcomes:\")\n",
    "print(f\"Weighted E[Y1]: {weighted_Y1}\")\n",
    "print(f\"Weighted E[Y2]: {weighted_Y2}\")\n",
    "print(f\"Weighted E[Y3]: {weighted_Y3}\")\n",
    "\n",
    "print(\"\\nCovariate Balance After Weighting (Standardized Mean Differences):\")\n",
    "print(smd_weighted_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Expected Outcomes:\n",
      "Weighted E[Y1]: 2.246950101786268\n",
      "Weighted E[Y2]: 1.2929983228108735\n",
      "Weighted E[Y3]: 0.9268150563338297\n",
      "\n",
      "Covariate Balance After Weighting (Standardized Mean Differences):\n",
      "         Z1        Z2        Z3\n",
      "0  0.010293  0.903805  0.914416\n",
      "1  0.014170  0.606045  0.315237\n",
      "2  0.007236  1.179601  0.874816\n",
      "3  0.006528  0.317556  0.571239\n",
      "4  0.008002  0.432347  0.554586\n"
     ]
    }
   ],
   "source": [
    "print(\"Weighted Expected Outcomes:\")\n",
    "print(f\"Weighted E[Y1]: {weighted_Y1}\")\n",
    "print(f\"Weighted E[Y2]: {weighted_Y2}\")\n",
    "print(f\"Weighted E[Y3]: {weighted_Y3}\")\n",
    "\n",
    "print(\"\\nCovariate Balance After Weighting (Standardized Mean Differences):\")\n",
    "print(smd_weighted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 23.6.0 23G93)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 5 rows, 200 columns and 1000 nonzeros\n",
      "Model fingerprint: 0xa082a03b\n",
      "Model has 200 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-04, 3e+00]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  QObjective range [2e+00, 2e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [0e+00, 0e+00]\n",
      "Presolve time: 0.00s\n",
      "Presolved: 5 rows, 200 columns, 1000 nonzeros\n",
      "Presolved model has 200 quadratic objective terms\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 1.000e+01\n",
      " Factor NZ  : 1.500e+01\n",
      " Factor Ops : 5.500e+01 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   5.00000000e+07 -5.00000000e+07  6.04e+04 0.00e+00  1.00e+06     0s\n",
      "   1   1.25464563e+07 -1.25464563e+07  6.11e+03 4.92e+01  1.83e+05     0s\n",
      "   2   2.63516192e+06 -2.63516192e+06  6.11e-03 0.00e+00  2.64e+04     0s\n",
      "   3   3.86080998e+05 -3.86080998e+05  6.11e-09 0.00e+00  3.86e+03     0s\n",
      "   4   5.65651353e+04 -5.65651353e+04  9.33e-13 4.88e-14  5.66e+02     0s\n",
      "   5   8.28741340e+03 -8.28741340e+03  3.37e-13 2.75e-14  8.29e+01     0s\n",
      "   6   1.21419647e+03 -1.21419647e+03  1.47e-13 8.88e-15  1.21e+01     0s\n",
      "   7   1.77892948e+02 -1.77892948e+02  9.63e-14 4.08e-15  1.78e+00     0s\n",
      "   8   2.60632351e+01 -2.60632351e+01  1.20e-14 1.52e-15  2.61e-01     0s\n",
      "   9   3.81854353e+00 -3.81854353e+00  1.85e-14 7.36e-16  3.82e-02     0s\n",
      "  10   5.59457396e-01 -5.59457396e-01  1.61e-15 2.19e-16  5.59e-03     0s\n",
      "  11   8.19664552e-02 -8.19664552e-02  6.83e-16 6.07e-17  8.20e-04     0s\n",
      "  12   1.20089534e-02 -1.20089534e-02  2.72e-16 1.99e-17  1.20e-04     0s\n",
      "  13   1.75943833e-03 -1.75943833e-03  1.11e-16 1.46e-17  1.76e-05     0s\n",
      "  14   2.57776206e-04 -2.57776206e-04  1.73e-17 3.74e-18  2.58e-06     0s\n",
      "  15   3.77669148e-05 -3.77669148e-05  2.32e-17 1.78e-18  3.78e-07     0s\n",
      "  16   5.53324750e-06 -5.53324750e-06  4.03e-18 6.10e-19  5.53e-08     0s\n",
      "  17   8.10678397e-07 -8.10678397e-07  3.75e-18 1.69e-19  8.11e-09     0s\n",
      "  18   1.18772809e-07 -1.18772809e-07  2.21e-18 1.25e-19  1.19e-09     0s\n",
      "  19   1.74014477e-08 -1.74014477e-08  5.17e-19 3.52e-20  1.74e-10     0s\n",
      "  20   2.54949209e-09 -2.54949209e-09  1.33e-19 1.50e-20  2.55e-11     0s\n",
      "\n",
      "Barrier solved model in 20 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective 2.54949209e-09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Simulation parameters\n",
    "N = 200  # Sample size\n",
    "K = 3  # Number of binary treatment factors\n",
    "D = 5  # Number of covariates\n",
    "rho = 0.2  # Correlation coefficient\n",
    "\n",
    "# Generate covariates X from a multivariate normal distribution\n",
    "mu = np.array([0.1, 0.1, 0.1, 0.0, 0.0])\n",
    "Sigma = np.full((D, D), rho)\n",
    "np.fill_diagonal(Sigma, 1)\n",
    "X = multivariate_normal.rvs(mean=mu, cov=Sigma, size=N)\n",
    "\n",
    "# Logistic regression coefficients\n",
    "beta1 = np.array([1/4, 2/4, 0, 3/4, 1])\n",
    "beta2 = np.array([3/4, 1/4, 1, 0, 2/4])\n",
    "beta3 = np.array([1, 0, 3/4, 2/4, 1/4])\n",
    "\n",
    "# Function to compute logistic probabilities\n",
    "def logistic_prob(X, beta):\n",
    "    logits = X @ beta\n",
    "    return 1 / (1 + np.exp(-logits))\n",
    "\n",
    "# Generate treatment assignments\n",
    "Z = np.zeros((N, K))\n",
    "for k, beta in enumerate([beta1, beta2, beta3]):\n",
    "    probs = logistic_prob(X, beta)\n",
    "    Z[:, k] = np.random.binomial(1, probs)\n",
    "\n",
    "# Generate potential outcomes\n",
    "epsilon = np.random.normal(0, 1, size=(N, 3))\n",
    "Z_expanded = np.repeat(Z, D // K + 1, axis=1)[:, :D]\n",
    "\n",
    "# Define outcome models\n",
    "# General Additive Outcome Model\n",
    "Y1 = 2 * np.sum(X, axis=1) + np.sum(Z, axis=1) + epsilon[:, 0]\n",
    "\n",
    "# Outcome Model with Treatment Effect Heterogeneity\n",
    "Y2 = 2 * np.sum(X, axis=1) + np.sum(X * Z_expanded, axis=1) + epsilon[:, 1]\n",
    "\n",
    "# Misspecified Outcome Model\n",
    "Y3 = np.sin(X[:, 0]) + np.cos(X[:, 1]) + (np.minimum(1, Y1) + X[:, 1]) * Z[:, 0] + np.sum(X * Z_expanded, axis=1) + epsilon[:, 2]\n",
    "\n",
    "# Initialize Gurobi model for optimization\n",
    "model = gp.Model(\"FactorialEffectOptimization\")\n",
    "w = model.addVars(N, lb=0.0, name=\"w\")\n",
    "\n",
    "# Objective function: Minimize entropy (x * log(x)) as m(w)\n",
    "model.setObjective(gp.quicksum(w[i] * w[i] for i in range(N)), GRB.MINIMIZE)\n",
    "\n",
    "# Defining balance constraints according to the equation in the image\n",
    "# Balance constraint for factorial effects\n",
    "for d in range(D):\n",
    "    treated_sum = gp.quicksum(w[i] * X[i, d] * Z[i, 0] for i in range(N))\n",
    "    control_sum = gp.quicksum(w[i] * X[i, d] * (1 - Z[i, 0]) for i in range(N))\n",
    "    model.addConstr(treated_sum - control_sum == 0, name=f\"balance_{d}\")\n",
    "\n",
    "# Solve the optimization problem\n",
    "model.optimize()\n",
    "\n",
    "# Extract optimal weights\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    w_opt = np.array([w[i].X for i in range(N)])\n",
    "else:\n",
    "    raise ValueError(\"Optimization did not converge!\")\n",
    "\n",
    "# Apply optimal weights to outcomes\n",
    "weighted_Y1 = np.sum(w_opt * Y1) / np.sum(w_opt)\n",
    "weighted_Y2 = np.sum(w_opt * Y2) / np.sum(w_opt)\n",
    "weighted_Y3 = np.sum(w_opt * Y3) / np.sum(w_opt)\n",
    "\n",
    "# Function to compute standardized mean differences (SMD)\n",
    "def compute_smd_weighted(X, Z_col, weights):\n",
    "    treated_mean = np.average(X[Z_col == 1], axis=0, weights=weights[Z_col == 1])\n",
    "    control_mean = np.average(X[Z_col == 0], axis=0, weights=weights[Z_col == 0])\n",
    "    pooled_sd = np.sqrt((np.average((X[Z_col == 1] - treated_mean) ** 2, axis=0, weights=weights[Z_col == 1]) +\n",
    "                         np.average((X[Z_col == 0] - control_mean) ** 2, axis=0, weights=weights[Z_col == 0])) / 2)\n",
    "    smd = np.abs(treated_mean - control_mean) / pooled_sd\n",
    "    return smd\n",
    "\n",
    "# Compute SMDs after weighting\n",
    "smd_weighted_results = {}\n",
    "for k in range(K):\n",
    "    smd_weighted_results[f'Z{k+1}'] = compute_smd_weighted(X, Z[:, k], w_opt)\n",
    "\n",
    "smd_weighted_df = pd.DataFrame(smd_weighted_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Main Effects: 0.5326814892645563\n",
      "RMSE for Interaction Effects: 0.0\n",
      "Weighted Outcomes and RMSE:\n",
      "    Outcome Model  Weighted Expected Outcome\n",
      "0       Additive                   2.564412\n",
      "1  Heterogeneous                   1.650722\n",
      "2   Misspecified                   1.359147\n",
      "\n",
      "Covariate Balance SMDs After Weighting:\n",
      "          Z1        Z2        Z3\n",
      "0  0.024732  0.572232  1.031147\n",
      "1  0.021637  0.513987  0.183483\n",
      "2  0.004735  1.345759  1.005478\n",
      "3  0.026358  0.102858  0.449505\n",
      "4  0.009602  0.471160  0.035176\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE for outcomes\n",
    "# Define true main effects based on simulation setup (as per Y1)\n",
    "true_main_effects = np.array([2] * D)  # Assuming true effects are 2 for all covariates in Y1\n",
    "true_interaction_effects = np.array([0] * (K * (K - 1) // 2))  # No true interaction effects assumed in Y1\n",
    "\n",
    "# Extract estimated effects (replace with actual estimates from your model)\n",
    "estimated_main_effects = np.array([weighted_Y1, weighted_Y2, weighted_Y3])\n",
    "\n",
    "# Calculate RMSE for main effects\n",
    "rmse_main_effects = np.sqrt(np.mean((estimated_main_effects - true_main_effects[:3])**2))\n",
    "\n",
    "# Assuming zero true interaction effects for simplicity in the additive model\n",
    "estimated_interaction_effects = np.array([0.0, 0.0, 0.0])  # Replace with actual interaction effect estimates\n",
    "rmse_interaction_effects = np.sqrt(np.mean((estimated_interaction_effects - true_interaction_effects) ** 2))\n",
    "\n",
    "# Display RMSE\n",
    "print(f\"RMSE for Main Effects: {rmse_main_effects}\")\n",
    "print(f\"RMSE for Interaction Effects: {rmse_interaction_effects}\")\n",
    "\n",
    "\n",
    "# Prepare results for output\n",
    "results_df = pd.DataFrame({\n",
    "    'Outcome Model': ['Additive', 'Heterogeneous', 'Misspecified'],\n",
    "    'Weighted Expected Outcome': [weighted_Y1, weighted_Y2, weighted_Y3],\n",
    "})\n",
    "\n",
    "# Display results\n",
    "print(\"Weighted Outcomes and RMSE:\\n\", results_df)\n",
    "print(\"\\nCovariate Balance SMDs After Weighting:\\n\", smd_weighted_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gurobi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
