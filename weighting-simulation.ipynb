{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "import scipy.sparse as sp\t\n",
    "from statsmodels.api import Logit\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of the simulation section of Yu's Balancing Weights Causal Inference in Observational Factorial Studies paper (Yu 5.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rseed = 42\n",
    "np.random.seed(rseed)\n",
    "n = 500 # set as 500, 1000, 2000\n",
    "rho = 0 # set as 0, 0.2, 0.4 for each scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the specification in Yu: \"the treatment assignment mechanism for $Z_{ik}$ is independent across $k$'s and satisfies a logistic regression that $P(Z_{ik} = 1) = \\frac{1}{(1+exp(-\\beta_k^T X_i))}$ where \"$\\beta_1 = (\\frac{1}{4}, \\frac{2}{4}, 0, \\frac{3}{4}, 1)$, $\\beta_2 = (\\frac{3}{4}, \\frac{1}{4}, 1, 0, \\frac{2}{4})$, $\\beta_3 = (1, 0, \\frac{3}{4}, \\frac{2}{4}, \\frac{1}{4})$.\"\n",
    "\n",
    "This treatment assignment ensures all $2^3=8$ treatment combination groups are non-empty and observed so that the paper's proposed weighting estimators are applicable. We additionally assume conditional independence of factors given covariates, and that only the main factors of the three treatments are non-negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mean vector (mu)\n",
    "mu = np.array([0.1, 0.1, 0.1, 0, 0]).T\n",
    "\n",
    "# Define covariance matrix (Sigma) with 5 covariates, defined as according to paper specifications\n",
    "#   - Diagonal filled with ones, rest with correlation coefficient rho\n",
    "Sigma = np.full((5, 5), rho)\n",
    "np.fill_diagonal(Sigma, 1)  \n",
    "\n",
    "# Generate covariates (X) from multivariate normal\n",
    "np.random.seed(rseed)\n",
    "X = multivariate_normal.rvs(mean=mu, cov=Sigma, size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define beta coefficients for treatment assignments to fulfill all treatment outcomes observed condition\n",
    "beta_1 = np.array([1/4, 2/4, 0, 3/4, 1])\n",
    "beta_2 = np.array([3/4, 1/4, 1, 0, 2/4])\n",
    "beta_3 = np.array([1, 0, 3/4, 2/4, 1/4])\n",
    "\n",
    "# Logistic function to generate treatment assignments\n",
    "def logistic_prob(X, beta):\n",
    "    return 1 / (1 + np.exp(-X @ beta))\n",
    "\n",
    "# Generate treatment assignments independently\n",
    "Z1 = np.random.binomial(1, logistic_prob(X, beta_1), size=n)\n",
    "Z2 = np.random.binomial(1, logistic_prob(X, beta_2), size=n)\n",
    "Z3 = np.random.binomial(1, logistic_prob(X, beta_3), size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our problem setup, we next consider three outcome models, with errors following standard normal distribution.\n",
    "    \n",
    "An additive outcome: \n",
    "$Y_{i1} = 2\\sum_{k=1}^5 X_{ik} + \\sum_{j=1}^3 Z_{ij} + \\epsilon_{i1}$ \n",
    "    \n",
    "A heterogeneous treatment effect outcome: \n",
    "$Y_{i2} = 2\\sum_{k=1}^5 X_{ik} + \\sum_{k=1}^5 X_{ik} \\sum_{j=1}^3 Z_{ij} + \\epsilon_{i2}$ \n",
    "    \n",
    "A misspecified outcome:\n",
    "$Y_{i3} = sin(X_{i1}) + cos(X_{i2}) + (min(1, X_{i1}) + X_{i2})Z_{i1} + \\sum_{k=1}^5 X_{ik} \\sum_{j=2}^3 Z_{ij} + \\epsilon_{i3}$\n",
    "\n",
    "Additionally, four estimators are implemented for each main effect $\\tau_k, k=1, 2, 3$ under each outcome model:\n",
    "- The additive regression estimator\n",
    "- The interaction regression estimator\n",
    "- The weighting estimator under general additive model assumption and covariate basis functions $h_s(X) = X_s, s=1,... 5$\n",
    "- The weighting estimator with balance constraints under the outcome model specification with treatment effect heterogeneity, and the same basis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://par.nsf.gov/servlets/purl/10337012 - Supplementary reading to learn more about regression based methods causal inference with factorial experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome Model Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, making the \"true\" outcomes Y1, Y2, Y3 according to the outcome models specified in each simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(rseed)\n",
    "# From top to bottom: defining general, heterogeneous treatment effect, and misspecified outcome models\n",
    "Y1 = 2*np.sum(X, axis=1) + Z1 + Z2 + Z3 + np.random.normal(0, 1, n)\n",
    "Y2 = 2*np.sum(X, axis=1) + np.sum(X, axis=1)*(Z1 + Z2 + Z3) + np.random.normal(0, 1, n)\n",
    "Y3 = np.sin(X[:,0]) + np.cos(X[:,1]) + (np.minimum(1, X[:,0]) + X[:,1]) * Z1 + np.sum(X, axis=1) * (Z2 + Z3) + np.random.normal(0, 1, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define three separate $N \\times 2^K$ potential outcomes matrices $Y_p$ for each outcome model , where $K=3$, the number of main effects under analysis. Then each row for a unit $i$ is representative of the potential outcomes for 8 different treatment combinations of the factors Z1, Z2, and Z3 under the specified outcome model. \n",
    "\n",
    "As part of this process we use an assignment matrix $W$ to encode the 8 possible different treatment combinations of Z1, Z2, Z3 main effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the assignment matrix W for the 8 different unique treatment combinations under 3 main effect factors\n",
    "W = np.array([[1, 1, 1, 1, 0, 0, 0, 0],  # Each column is a unique treatment combination from 3 binary factors, each row is a factor\n",
    "             [1, 1, 0, 0, 1, 1, 0, 0],\n",
    "             [1, 0, 1, 0, 1, 0, 1, 0]])\n",
    "treat_combs = W.shape[1]\n",
    "Y1_out = np.zeros((n, treat_combs))\n",
    "Y2_out = np.zeros((n, treat_combs))\n",
    "Y3_out = np.zeros((n, treat_combs))\n",
    "z1, z2, z3 = W\n",
    "for i in range(n):\n",
    "    Y1_out[i] = 2*np.sum(X[i]) + z1 + z2 + z3 + np.random.normal(0, 1)\n",
    "    Y2_out[i] = 2*np.sum(X[i]) + np.sum(X[i])*(z1 + z2 + z3) + np.random.normal(0, 1)\n",
    "    Y3_out[i] = np.sin(X[i,0]) + np.cos(X[i,1]) + (np.minimum(1, X[i,0]) + X[i,1]) * z1 + np.sum(X[i]) * (z2 + z3) + np.random.normal(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following Dasgupta et al. [2015], all potential outcomes for a unit $i$ are comprised of a vector $Y_i$ of dimension $J$, with $J=2^K$ the number of possible values for $z$, the treatment assignment. Then $Y_i(z)$ denotes the potential outcome of the $i$ th unit when exposed to treatment $z$.\n",
    "\n",
    "We then define an $N \\times 2^K$ potential outcomes matrix $Y$ such that the $i$ th row is a $J$-vector.\n",
    "\n",
    "We've encoded this relationship into the three separate potential outcomes matrices Y1_out, Y2_out, and Y3_out for each outcome model, such that each row Yk_out(i) is a vector of length 8, for the 8 possible combinations of 3 treatments.\n",
    "\n",
    "We then define a contrast vector g. The purpose of the contrast vector is to create a difference between \"one half of the potential outcomes with the other half of potential outcomes\" i.e, each main effect then being the \"difference of the averages of the potential outcomes when (a factor) is at its high level and at its low level\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define contrasts vector as all possible treatment assignments\n",
    "g = np.array([[1, 1, 1, 1, -1, -1, -1, -1],  # Each row is a unique treatment combination from 3 binary factors, each column is a factor\n",
    "             [1, 1, -1, -1, 1, 1, -1, -1],\n",
    "             [1, -1, 1, -1, 1, -1, 1, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main effect of each treatment $z_k$, $\\tau_k$ is a comparison between the average potential outcomes of receiving treatment $z_k$ and the average potential outcomes of note receiving it, averaged over all treatment combinations of other factors, expressed as:\n",
    "\n",
    "$\\tau_k = \\frac{1}{2^{K-1}} g_k^T E[Y]$. \n",
    "\n",
    "Where $E[Y] = (E[Y(z)])_{z\\in Z}$.\n",
    "\n",
    "For the purposes of this simulation, we don't attempt to derive the interaction effects $\\tau_{k, k'}$ which measure the interaction between two factors $z_k$ and $z_k'$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using OLS for implementing additive regression $\\hat{\\beta} = (X^T X)^-1 X^T Y$ on all three outcome models. Specifically, we yield the additive regression main effect estimates for $\\tau_k, k=1, 2, 3$ by regressing our outcome variable $Y$, specified by outcome model, on the covariates $X$ and treatments $Z$ for $j=1,...,5$, $k=1, 2, 3$ and multiplying the coefficient for Z by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated factorial effects (additive model) for Y1 [1.75483927 1.83782051 2.04853169]\n",
      "\n",
      "Estimated factorial effects (additive model) for Y2 [1.78935311 0.25075834 1.62555032]\n",
      "\n",
      "Estimated factorial effects (additive model) for Y3 [0.77700929 0.55546364 1.37131804]\n"
     ]
    }
   ],
   "source": [
    "# Implementing the additive regression model:\n",
    "X_design = np.column_stack(((np.ones(n)), X, Z1, Z2, Z3))\n",
    "reg1_res = []\n",
    "for i, y in enumerate([Y1, Y2, Y3]):\n",
    "    beta_hat = np.linalg.inv(X_design.T @ X_design) @ X_design.T @ y\n",
    "    print(f\"\\nEstimated factorial effects (additive model) for Y{i+1}\", 2*beta_hat[6:])\n",
    "    reg1_res.append(2*beta_hat[6:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now adding interaction terms between covariates and treatment assignments, although we only recover the main effects as non-negligible coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated factorial effects (interaction model) for Y1 [1.76217942 1.85778257 2.02815107]\n",
      "\n",
      "Estimated factorial effects (interaction model) for Y2 [ 0.36005522 -0.37283454  0.31776519]\n",
      "\n",
      "Estimated factorial effects (interaction model) for Y3 [-0.20459922  0.06696588  0.19336125]\n"
     ]
    }
   ],
   "source": [
    "# Implementing the interaction regression model:\n",
    "XZ_interaction_terms = np.hstack([(X[:, j:j+1] * Z1.reshape(-1, 1)) for j in range(5)] +\n",
    "                              [(X[:, j:j+1] * Z2.reshape(-1, 1)) for j in range(5)] +\n",
    "                              [(X[:, j:j+1] * Z3.reshape(-1, 1)) for j in range(5)])\n",
    "\n",
    "X_design = np.column_stack(((np.ones(n)), X, Z1, Z2, Z3, XZ_interaction_terms))\n",
    "\n",
    "# Displaying estimated coefficients\n",
    "reg2_res = []\n",
    "for i, y in enumerate([Y1, Y2, Y3]):\n",
    "    beta_hat = np.linalg.inv(X_design.T @ X_design) @ X_design.T @ y\n",
    "    print(f\"\\nEstimated factorial effects (interaction model) for Y{i+1}\", 2*beta_hat[6:9])\n",
    "    reg2_res.append(2*beta_hat[6:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using Gurobi to implement the proposed weighting method, but first we have to set up the balancing constraints. We simulate using both the additive balance constraints and the interaction balance constraints. We use basis functions $h_s(X) = X_s$, meaning basis functions as just the unmodified, corresponding covariate column to each $s\\in S $; the raw value of the covariate. From this we define the following balancing constraints:\n",
    "\n",
    "We've already defined a contrast vector $g_k=(g_{kz})_{z \\in Z}$, a $2^K$ dimensional vector with half +1s and half -1s, indicating if a combination has $z_k = +1$ or $z_k = -1$. Given that we're only considering main effects we only devise a contrast vector accounting for all $2^3 = 8$ possible treatment combinations, with 3 binary factors.\n",
    "\n",
    "For our balancing constraints, we specifically decompose $g_{Kz}$, the contrast coefficient of the expected potential outcome under treatment combination $z$, as $g_Kz = g_{Kz}^{+} - g_{Kz}^{-}$. $g_{Kz}^{+} = max(g_{Kz}, 0)$ and $g_{Kz}^{-} = max(-g_{Kz}, 0)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_p = np.maximum(g, 0)  # Computes element wise maximum to decompose the contrast vector\n",
    "g_m = np.maximum(-g, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let $I(Z_i = z)$ be an indicator for whether an individual $i$ received treatment combination $z$.\n",
    "\n",
    "We then let $A_{iK}^{\\Omega} = \\sum_{z\\in Z} g_{Kz}^{\\Omega} I(Z_i = z)$ denote whether an individual belongs to the positive or negative part of the contrast $g_K$, with $\\Omega=+, -$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define indicator vector -- since we only have the single contrast vector for main effects, have two A vectors\n",
    "p = g.shape[0]\n",
    "A_p = np.zeros((n, p))\n",
    "A_m = np.zeros((n, p))\n",
    "for i in range(n): # iterate through all individuals\n",
    "    # obs = (Z1[i], Z2[i], Z3[i])\n",
    "    ind = -1\n",
    "    for j in range(g.shape[1]):\n",
    "        if Z1[i] == g_p[0, j] and Z2[i] == g_p[1, j] and Z3[i] == g_p[2, j]:\n",
    "            ind = j\n",
    "            break\n",
    "    if ind != -1:\n",
    "        for k in range(g.shape[0]):\n",
    "            if g_p[k, ind] == 1:\n",
    "                A_p[i, k] = 1  # assign to indicate positive part of contrast vector\n",
    "            else:\n",
    "                A_m[i, k] = 1  # assign to indicate negative part of contrast vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a basis function $q_{sJ}(X_i, Z_i) = h_s(X_i) \\Pi_{j \\in J} Z_{ij}, s = 1,..., S, J \\in [K]_{K'}$ Because we only consider the main effects non-negligible / non-zero, then $K' = 1$. The specific covariate basis function is $h_s(X) = X_s, s=1, ..., 5$, meaning the basis function used is just each of the five covariates themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can just define them outright\n",
    "h = np.copy(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Treatment Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define nine true treatment effects $\\tau_k$: one for each factor level (Z1, Z2, Z3) for each outcome model (general additive, heterogeneous treatment effect, misspecified model). This is built on a framework discussed in Dasgupta et al. [2015], and is further used in the Yu paper for deriving the treatment effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.64511961,  0.64511961,  0.64511961,  0.64511961, -0.64511961,\n",
       "       -0.64511961, -0.64511961, -0.64511961])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_mod1 = g[0] * np.mean(Y1) / 4 # 2**K-1 = 2**3 total factors - 1 = 2**2 = 4\n",
    "tau_mod1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65442353 0.7044147  0.65079244]\n",
      "[0.91975073 0.93248899 0.87557842]\n",
      "[0.51087006 0.56527522 0.53524538]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.65442353, 0.7044147 , 0.65079244]),\n",
       " array([0.91975073, 0.93248899, 0.87557842]),\n",
       " array([0.51087006, 0.56527522, 0.53524538])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1_tau = np.mean(np.multiply(Y1[:, np.newaxis], A_p), axis=0) / 4\n",
    "Y2_tau = np.mean(np.multiply(Y2[:, np.newaxis], A_p), axis=0) / 4\n",
    "Y3_tau = np.mean(np.multiply(Y3[:, np.newaxis], A_p), axis=0) / 4\n",
    "tau = [Y1_tau, Y2_tau, Y3_tau]\n",
    "print(Y1_tau)\n",
    "print(Y2_tau)\n",
    "print(Y3_tau)\n",
    "tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing results for additive regression: \n",
      "\n",
      "Y1 result: [1.75483927 1.83782051 2.04853169]\n",
      "Tau res: [0.65442353 0.7044147  0.65079244]\n",
      "RMSE Y1: 1.4830661772421916\n",
      "\n",
      "Y2 result: [1.78935311 0.25075834 1.62555032]\n",
      "Tau res: [0.91975073 0.93248899 0.87557842]\n",
      "RMSE Y2: 0.5944742758847122\n",
      "\n",
      "Y3 result: [0.77700929 0.55546364 1.37131804]\n",
      "Tau res: [0.51087006 0.56527522 0.53524538]\n",
      "RMSE Y3: 0.256647947746829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Showing results for additive regression: \\n\")\n",
    "for i in range(len(reg1_res)):\n",
    "    print(f\"Y{i+1} result: {reg1_res[i]}\")\n",
    "    print(f\"Tau res: {tau[i]}\")\n",
    "    rmse = np.mean(np.power(reg1_res[i] - tau[i], 2))\n",
    "    print(f\"RMSE Y{i+1}: {rmse}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing results for interactive regression: \n",
      "\n",
      "Y1 result: [1.76217942 1.85778257 2.02815107]\n",
      "Tau res: [0.65442353 0.7044147  0.65079244]\n",
      "RMSE Y1: 1.4848324462839775\n",
      "\n",
      "Y2 result: [ 0.36005522 -0.37283454  0.31776519]\n",
      "Tau res: [0.91975073 0.93248899 0.87557842]\n",
      "RMSE Y2: 0.7760947306769838\n",
      "\n",
      "Y3 result: [-0.20459922  0.06696588  0.19336125]\n",
      "Tau res: [0.51087006 0.56527522 0.53524538]\n",
      "RMSE Y3: 0.29236441737917257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Showing results for interactive regression: \\n\")\n",
    "for i in range(len(reg2_res)):\n",
    "    print(f\"Y{i+1} result: {reg2_res[i]}\")\n",
    "    print(f\"Tau res: {tau[i]}\")\n",
    "    rmse = np.mean(np.power(reg2_res[i] - tau[i], 2))\n",
    "    print(f\"RMSE Y{i+1}: {rmse}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
